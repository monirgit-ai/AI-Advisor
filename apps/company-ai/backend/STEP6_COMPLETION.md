# STEP 6 COMPLETION NOTE â€” RAG Indexing + Semantic Search

**Date:** 2026-01-17  
**Status:** âœ… COMPLETE  
**Phase:** RAG Indexing + Semantic Search (Phase-1 MVP)

---

## âœ… IMPLEMENTATION SUMMARY

Step 6 has been successfully completed. All required components for document chunking, embedding generation, vector storage, and semantic search are implemented and ready for testing.

**This step transforms the system into an AI-powered RAG (Retrieval-Augmented Generation) platform.**

---

## ğŸ“‹ COMPLETED COMPONENTS

### 1. Configuration Updates âœ…

**Location:** `app/core/config.py`

- **OLLAMA_BASE_URL:** `http://127.0.0.1:11434` (configurable via env)
- **OLLAMA_EMBED_MODEL:** `nomic-embed-text` (768-dimensions)
- All settings environment-configurable

### 2. Database Models âœ…

#### A) DocumentChunk Model (`app/db/models/document_chunk.py`)

**Schema:**
- `id` (UUID, primary key, indexed)
- `company_id` (FK â†’ companies.id, indexed) - Multi-tenant isolation
- `document_id` (FK â†’ documents.id, indexed)
- `chunk_index` (int) - Order of chunk in document
- `text` (TEXT) - Chunk content
- `token_estimate` (int, nullable) - Simple estimate (~4 chars/token)
- `embedding` (Vector(768)) - **Fixed 768 dimensions for nomic-embed-text**
- `created_at` (timestamp)

**Relationships:**
- `company` â†’ Company model
- `document` â†’ Document model

#### B) Document Model Updates (`app/db/models/document.py`)

**Added Fields:**
- `index_status` (enum: `not_indexed`, `indexing`, `indexed`, `failed`)
- `index_error` (Text, nullable) - Error message if indexing fails

**New Enum:**
- `IndexStatus` - Tracks document indexing state

### 3. Chunking Service âœ…

**Location:** `app/services/chunking.py`

**Function:** `chunk_text(text, chunk_size=1000, overlap=150)`

**Features:**
- **Chunk Size:** Default 1000 characters (configurable 800-1200 range)
- **Overlap:** Default 150 characters (configurable 100-200 range)
- **Smart Splitting:**
  - Primary: Split by paragraphs (double newline)
  - Fallback: Split by sentences
  - Final fallback: Split by words (for very long sentences)
- **Overlap Handling:** Preserves context between chunks
- **Size Enforcement:** Ensures all chunks within limits

**Algorithm:**
1. Try paragraph-based splitting first
2. For oversized paragraphs, use sentence splitting
3. For oversized sentences, use word splitting
4. Maintain overlap from previous chunk
5. Filter out empty chunks

### 4. Embeddings Service âœ…

**Location:** `app/services/embeddings.py`

**Class:** `OllamaEmbedder`

**Features:**
- Calls Ollama `/api/embed` endpoint
- Model: `nomic-embed-text` (768 dimensions)
- Single text embedding: `embed(text) -> List[float]`
- Batch embedding: `embed_batch(texts) -> List[List[float]]`
- Error handling with logging
- Timeout: 60 seconds per request
- Dimension validation

**API Call Format:**
```python
POST http://127.0.0.1:11434/api/embed
Body: {"model": "nomic-embed-text", "input": "<text>"}
Response: {"embedding": [<768 floats>]}
```

### 5. Indexing Service âœ…

**Location:** `app/services/indexer.py`

**Function:** `index_document(document_id, company_id, db) -> (success, error, chunks_created)`

**Pipeline:**
1. **Load Document:** Verify exists and belongs to company
2. **Check Text:** Ensure `text_extracted` exists
3. **Update Status:** Set `index_status = "indexing"`
4. **Delete Existing:** Remove old chunks for this document
5. **Chunk Text:** Split into overlapping chunks
6. **Generate Embeddings:** Batch embed all chunks via Ollama
7. **Store Chunks:** Create DocumentChunk records with vectors
8. **Update Status:** Set to `indexed` or `failed`
9. **Error Handling:** Capture errors in `index_error` field

**Features:**
- Synchronous processing (MVP approach)
- Company-scoped validation
- Robust error handling
- Status tracking throughout process
- Chunk deduplication (delete before re-index)

### 6. Search API Endpoint âœ…

**Location:** `app/api/search.py`

#### POST /search

**Request:**
```json
{
  "query": "search text",
  "top_k": 5,
  "document_id": "optional-uuid"  // Optional filter
}
```

**Response:**
```json
{
  "results": [
    {
      "chunk_id": "...",
      "document_id": "...",
      "chunk_index": 0,
      "text": "chunk text...",
      "similarity_score": 0.95,
      "document_filename": "...",
      "token_estimate": 250
    }
  ],
  "total_results": 5
}
```

**Features:**
- **JWT Authentication:** Required via `get_current_user`
- **Company Scoping:** Only searches user's company documents
- **Cosine Similarity:** Uses pgvector `<=>` operator
- **Vector Search:** Embeds query, compares with stored embeddings
- **Optional Filtering:** Can filter by `document_id`
- **Top-K Results:** Configurable (1-50, default 5)
- **Similarity Scores:** Returns cosine similarity (0-1 range)
- **Document Context:** Includes source document filename

**Implementation:**
- Uses raw SQL with pgvector operators for performance
- `1 - (embedding <=> query_vec)` for cosine similarity
- ORDER BY similarity DESC
- JOIN with documents table for filename lookup

### 7. Document Indexing Endpoint âœ…

**Location:** `app/api/documents.py`

#### POST /documents/{document_id}/index

**Features:**
- **JWT Authentication:** Required
- **Company Validation:** Ensures document belongs to user's company
- **Triggers Indexing:** Calls `index_document()` service
- **Status Updates:** Returns current index status

**Response:**
```json
{
  "document_id": "...",
  "status": "indexed",
  "chunks_created": 15,
  "index_status": "indexed"
}
```

### 8. Dependencies âœ…

**Location:** `requirements.txt`

**Added:**
- `requests` - For Ollama API calls
- `pgvector` - PostgreSQL vector extension support

**Status:** All dependencies listed and ready for installation

### 9. API Wiring âœ…

**Location:** `app/api/__init__.py`

- Search router included in main `api_router`
- Prefix: `/search`
- Tag: `search`

**API Structure:**
```
/api
  â”œâ”€â”€ /auth (authentication)
  â”œâ”€â”€ /documents (document management + indexing)
  â”œâ”€â”€ /search (semantic search)
  â””â”€â”€ /health (health check)
```

---

## ğŸ” SECURITY FEATURES

### Authentication
- âœ… JWT token required for all endpoints
- âœ… Token validated on every request
- âœ… User must be active

### Company Isolation
- âœ… All chunks scoped by `company_id`
- âœ… Search results filtered by user's company
- âœ… Indexing validates company ownership
- âœ… Cross-company access blocked

### Data Privacy
- âœ… All embeddings generated locally (Ollama)
- âœ… No external API calls for embeddings
- âœ… Documents never leave the server
- âœ… Vector data stored in company's database

---

## ğŸ—„ï¸ DATABASE REQUIREMENTS

### pgvector Extension

**Required:** PostgreSQL with pgvector extension enabled

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### IVFFlat Index (Recommended)

For fast similarity search, create IVFFlat index:

```sql
CREATE INDEX IF NOT EXISTS document_chunks_embedding_idx 
ON document_chunks 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

**Note:** Index creation happens in migration (manual step required)

**Tuning Note:** `lists = 100` is fine for MVP. When document chunks exceed 100k, consider tuning the `lists` parameter or migrating to HNSW index for better performance at scale.

### Vector Column

- **Type:** `vector(768)` - Fixed dimension
- **Model:** nomic-embed-text (768 dimensions)
- **Operator Class:** `vector_cosine_ops` for cosine similarity

---

## ğŸ¤– OLLAMA REQUIREMENTS

### Installation

Ollama must be installed and running on the server:

```bash
# Check installation
ollama --version

# Start server (if not running)
ollama serve

# Pull embedding model
ollama pull nomic-embed-text
```

### Model Specifications

- **Model:** `nomic-embed-text`
- **Dimensions:** 768
- **API Endpoint:** `http://127.0.0.1:11434/api/embed`
- **Format:** JSON request/response

### Performance Considerations

- **Embedding Time:** ~50-200ms per chunk (CPU-dependent)
- **Batch Processing:** Sequential for MVP (can be parallelized later)
- **Timeout:** 60 seconds per request
- **Memory:** Model requires ~500MB RAM

---

## ğŸ“Š INDEXING PIPELINE

### Flow Diagram

```
Document (text_extracted)
    â†“
Chunk Text (1000 chars, 150 overlap)
    â†“
Generate Embeddings (Ollama API)
    â†“
Store Chunks + Vectors (PostgreSQL)
    â†“
Update Document Status (indexed/failed)
```

### Status Tracking

1. **not_indexed** - Initial state
2. **indexing** - Process started
3. **indexed** - Successfully completed
4. **failed** - Error occurred (see `index_error`)

### Error Handling

- Failed embeddings: Logged, chunk skipped
- API errors: Captured in `index_error`
- Partial failures: Some chunks indexed, error logged
- Re-indexing: Deletes old chunks before creating new ones

---

## ğŸ§ª TESTING STATUS

### âœ… Code Implementation

- [x] All models created
- [x] All services implemented
- [x] All endpoints created
- [x] API routers wired
- [x] Dependencies added
- [x] Error handling in place

### â³ Pending (Requires Migration + Ollama)

- [ ] Database migration generated and applied
- [ ] pgvector extension enabled
- [ ] IVFFlat index created
- [ ] Ollama model pulled
- [ ] End-to-end testing (upload â†’ index â†’ search)

### Test Flow

1. **Upload Document:**
   ```bash
   POST /documents/upload
   â†’ Returns document_id
   ```

2. **Index Document:**
   ```bash
   POST /documents/{document_id}/index
   â†’ Creates chunks, generates embeddings, stores vectors
   â†’ Returns chunks_created count
   ```

3. **Search:**
   ```bash
   POST /search
   Body: {"query": "search text", "top_k": 5}
   â†’ Returns top chunks with similarity scores
   ```

---

## ğŸ”§ TECHNICAL NOTES

### Chunking Strategy

- **Primary:** Paragraph-based (preserves context)
- **Fallback:** Sentence-based (for long paragraphs)
- **Final:** Word-based (for long sentences)
- **Overlap:** 150 chars ensures context continuity

### Embedding Generation

- **Model:** nomic-embed-text (768-dim, CPU-optimized)
- **API:** Synchronous calls (MVP approach)
- **Error Handling:** Graceful degradation (skips failed chunks)
- **Validation:** Dimension checking (must be 768)

### Vector Search

- **Similarity:** Cosine similarity (1 - cosine distance)
- **Index:** IVFFlat for fast approximate search
- **Query:** Embed query text, compare with stored vectors
- **Filtering:** Company-scoped + optional document filter

### Performance Considerations

**MVP (Current):**
- Synchronous processing
- Sequential embedding generation
- IVFFlat index with `lists = 100` (good enough for MVP)
- Clean abstraction for batch embedding (ready for parallelization)

**Future Optimizations (Step 8+):**
- **IVFFlat Tuning:** When chunks > 100k, tune `lists` parameter or migrate to HNSW
- **Parallel Embedding:** Use Celery/background workers for batch processing
- **HNSW Index:** Faster, more accurate for large-scale deployments
- **Async Indexing:** Background processing pipeline
- **Batch Operations:** Optimize for bulk indexing

**Design Note:** Current implementation keeps it simple for MVP. Clean abstractions allow future parallelization without major refactoring.

---

## ğŸ“ PROJECT STRUCTURE

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py          # âœ“ Includes search router
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ deps.py
â”‚   â”‚   â”œâ”€â”€ documents.py         # âœ“ Includes index endpoint
â”‚   â”‚   â”œâ”€â”€ search.py            # âœ“ Semantic search endpoint
â”‚   â”‚   â””â”€â”€ health.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py            # âœ“ Ollama settings
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â””â”€â”€ security.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chunking.py          # âœ“ Text chunking service
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # âœ“ Ollama embedder
â”‚   â”‚   â””â”€â”€ indexer.py           # âœ“ Document indexing orchestration
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ session.py
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ __init__.py      # âœ“ Exports DocumentChunk
â”‚   â”‚       â”œâ”€â”€ company.py
â”‚   â”‚       â”œâ”€â”€ user.py
â”‚   â”‚       â”œâ”€â”€ document.py      # âœ“ Added index_status/error
â”‚   â”‚       â””â”€â”€ document_chunk.py # âœ“ Vector storage model
â”‚   â””â”€â”€ ...
â”œâ”€â”€ alembic/
â”‚   â”œâ”€â”€ env.py                   # âœ“ Imports DocumentChunk
â”‚   â””â”€â”€ versions/                # Migration to be generated
â””â”€â”€ requirements.txt             # âœ“ Added requests, pgvector
```

---

## ğŸš€ NEXT STEPS

### Immediate (Required for Testing)

1. **Enable pgvector Extension:**
   ```bash
   psql -U companyai_user -d companyai -c "CREATE EXTENSION IF NOT EXISTS vector;"
   ```

2. **Install Ollama Model:**
   ```bash
   ollama pull nomic-embed-text
   ```

3. **Generate Migration:**
   ```bash
   alembic revision --autogenerate -m "Add document chunks and index status"
   ```

4. **Add IVFFlat Index:**
   Edit migration file to include:
   ```sql
   CREATE INDEX document_chunks_embedding_idx 
   ON document_chunks 
   USING ivfflat (embedding vector_cosine_ops) 
   WITH (lists = 100);
   ```

5. **Run Migration:**
   ```bash
   alembic upgrade head
   ```

### Ready For (Step 7+)

- LLM answer generation
- Chat UI integration
- Prompt orchestration
- Agent logic
- Context window management

### Not Yet Implemented (As Per Requirements)

- âŒ Chunking strategies beyond basic overlap
- âŒ Multiple embedding models
- âŒ HNSW index (using IVFFlat for MVP)
- âŒ Async indexing pipeline
- âŒ Embedding caching
- âŒ Query result reranking

---

## âœ… VERIFICATION CHECKLIST

- [x] Configuration updated with Ollama settings
- [x] DocumentChunk model created with vector(768)
- [x] Document model updated with index_status/error
- [x] Chunking service implemented
- [x] Embeddings service implemented (Ollama)
- [x] Indexing service implemented
- [x] Search endpoint created
- [x] Index endpoint added to documents router
- [x] All dependencies added to requirements.txt
- [x] API routers wired correctly
- [ ] Database migration generated (pending)
- [ ] pgvector extension enabled (pending)
- [ ] IVFFlat index created (pending)
- [ ] Ollama model installed (pending)
- [ ] End-to-end testing completed (pending)

---

## ğŸ“ COMMANDS FOR TESTING

### 1. Setup

```bash
# Install dependencies
cd /home/aiapp/apps/company-ai/backend
source ../venv/bin/activate
pip install -r requirements.txt

# Enable pgvector
psql -U companyai_user -d companyai -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Pull Ollama model
ollama pull nomic-embed-text
```

### 2. Generate and Run Migration

```bash
# Generate migration
alembic revision --autogenerate -m "Add document chunks and index status"

# Edit migration file to add IVFFlat index (see MIGRATION_INSTRUCTIONS.md)

# Run migration
alembic upgrade head
```

### 3. Test Flow

```bash
# Start server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 1. Login
TOKEN=$(curl -s -X POST http://127.0.0.1:8000/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@example.com","password":"admin123"}' \
  | grep -o '"access_token":"[^"]*"' | cut -d'"' -f4)

# 2. Upload document
curl -X POST http://127.0.0.1:8000/documents/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@test_document.txt"

# 3. Index document (use document_id from upload response)
curl -X POST http://127.0.0.1:8000/documents/{document_id}/index \
  -H "Authorization: Bearer $TOKEN"

# 4. Search
curl -X POST http://127.0.0.1:8000/search \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"query": "test query text", "top_k": 5}'
```

---

## ğŸ¯ SUMMARY

**Step 6 is code-complete and ready for migration + testing.**

All RAG indexing and semantic search components are:
- âœ… Implemented
- âœ… Documented
- âœ… Ready for integration

The system can now:
- Chunk documents with overlap-aware splitting
- Generate embeddings locally via Ollama
- Store vectors in PostgreSQL pgvector
- Perform semantic search with cosine similarity
- Maintain company-scoped isolation throughout

**Key Achievements:**
- AI-powered RAG infrastructure complete
- Local-only embeddings (privacy-preserving)
- Multi-tenant vector storage
- Semantic search with similarity scores
- Status tracking for indexing pipeline

**Status:** âœ… CODE COMPLETE - PENDING MIGRATION + OLLAMA SETUP

**Next:** Generate migration, enable pgvector, pull Ollama model, test end-to-end flow.

---

**Prepared by:** AI Assistant  
**Reviewed by:** [Supervisor]  
**Date:** 2026-01-17
